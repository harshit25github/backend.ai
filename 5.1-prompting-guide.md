# GPT‑5.1 Prompting Guide — Field Notes (Paraphrased)

> Source: https://cookbook.openai.com/examples/gpt-5/gpt-5-1_prompting_guide  
> This README is an **extensive, practical, paraphrased** digest of the guide, focused on “what to do in prompts” and “why it works.”  
> (I intentionally avoid long verbatim copying; templates below are rewritten in my own words.)

---

## 1) What GPT‑5.1 is optimized for (high-level takeaways)

- **Balance of speed + capability** for agentic workflows and coding tasks.
- **Better calibration to prompt difficulty**: tends to spend fewer tokens on easy inputs and handle hard inputs more efficiently.
- **More steerable** for personality, tone, formatting, and “how chatty vs how direct” behavior.
- Adds a new reasoning option: **`none`** (see §4.3) for low-latency / “non‑reasoning” style interactions.

---

## 2) Migrating to GPT‑5.1

### 2.1 If you’re coming from GPT‑4.1
- GPT‑5.1 + **`reasoning: none`** is positioned as a natural swap for many low‑latency flows that **don’t need deep reasoning**.

### 2.2 If you’re coming from GPT‑5
Common migration wins come from being explicit about:

1) **Persistence / completeness**  
   - GPT‑5.1 can sometimes stop early or be *too concise* on long tasks.  
   - Counter it by instructing: “finish end‑to‑end, don’t stop at partial progress, don’t require me to nudge you to continue.”

2) **Output formatting + verbosity**  
   - GPT‑5.1 can be very detailed; it’s worth defining “how long is too long,” and specifying what the final answer should look like.

3) **Coding agent tooling**  
   - If you’re using patch-style code edits, migrate to the **named** `apply_patch` tool style in GPT‑5.1 (see §6.1).

4) **Instruction following**  
   - GPT‑5.1 is strong at instruction adherence, so most behavior problems are solved by:
     - removing conflicting rules,
     - being specific about priorities,
     - and clarifying “must/should/may” in edge cases.

### 2.3 Note: GPT‑5.1‑codex
- OpenAI also released **GPT‑5.1‑codex**, which behaves differently.  
  If your workload is heavily “coding agent” oriented, check the Codex prompting guide too.

---

## 3) Agentic steerability (personality, verbosity, user updates)

### 3.1 Define a *clear persona* for stable behavior
The guide’s key idea: steering is best when you provide a crisp “persona contract,” especially for customer-facing agents:
- match user tone without being over-the-top,
- avoid repetitive “acknowledgement tokens” (e.g., “Got it!” every turn),
- keep the conversation moving (“respect through momentum”).

**Implementation pattern:** Add a “persona” section in the system prompt with:
- how to acknowledge (when to do it, when to skip it),
- the default cadence (brisk vs spacious),
- how to behave when stakes are high (drop fluff, move to resolution).

### 3.2 Control output length in two layers
1) **Model parameter**: use a `verbosity` control if available in your integration.  
2) **Prompt-based constraints**: give concrete, enforceable caps.

**Practical “length spec” pattern**
- For tiny changes: 2–5 sentences or ≤3 bullets, no headings, max 1 tiny snippet only if essential.
- For medium changes: a short list or short paragraph, max 1–2 small snippets total.
- For big multi-file changes: summarize per file; avoid inlining long code blocks.

**Extra finishing rules that help:**
- Don’t paste logs or “I ran tests” narration unless asked or truly blocking.
- Prefer file/symbol references over code fences.
- Avoid multi-section recaps for simple work; use a compact “What / Where / Outcome”.

### 3.3 “User updates” (preambles) for long tool runs
The guide calls these **user updates / preambles**: short progress notes that help users supervise an agentic rollout.

**Axes you can tune**
- frequency,
- verbosity,
- tone,
- content.

**A solid default spec**
- Before first tool call: post a quick plan (goal + constraints + next steps).
- During work: send a 1–2 sentence update every few tool calls **when something meaningful changes**.
- Force an update at a maximum cadence (example in the guide: after ~6 execution steps or ~8 tool calls).
- If you go “heads‑down” for a while, say why + when you’ll report back; then summarize what you learned.
- Every update should include at least **one concrete new outcome** since the last update (“found X”, “confirmed Y”), not only next steps.
- In the final recap: include a checklist of the planned items and ensure none are left hanging.
- If your plan changes, say so explicitly.

---

## 4) Optimizing intelligence + instruction following

### 4.1 Prevent “premature stopping” on long tasks (solution persistence)
A recommended prompt block is essentially:
- behave like an autonomous senior pair programmer,
- once you have direction, do the multi-step work without asking permission at every step,
- finish the job end‑to‑end inside the current turn when feasible,
- be biased toward action, not stalling.

**Useful nuance**
- If user intent is “somewhat ambiguous,” prefer making a reasonable default move rather than punting back questions.
- If the user asks “Should we do X?” and the answer is yes, proceed to do it instead of waiting for “please do X.”

### 4.2 Tool-calling: make tools easy to use correctly
The guide repeatedly emphasizes:
- Put the **what** in the tool definition (clear description, strict schema).
- Put the **when/how** in the system prompt (rules + examples).
- Use “MUST/DO NOT” language for safety-critical decisions.

**Example pattern (restaurant reservation)**
- Define a `create_reservation(name, datetime)` tool.
- Add explicit tool usage rules:
  - call it when user asks to book/reserve,
  - don’t guess missing fields; ask concise questions for missing parts,
  - after a tool call, confirm naturally with the returned confirmation data.
- Include 2–3 short few-shot examples covering:
  - all fields provided,
  - missing fields,
  - “tonight at 6” style times.

### 4.3 Parallel tool calling
GPT‑5.1 handles **parallel tool calls** better.
- Encourage batching/parallelism in the tool descriptions (e.g., “batch read_file calls”).
- Reinforce it in the system prompt with an explicit instruction like:
  - “Parallelize tool calls whenever possible; batch reads and edits.”

### 4.4 Using `reasoning: none` for efficiency
`none` is a new mode that **never uses reasoning tokens**, designed to behave closer to classic “non‑reasoning” models. Despite that:
- you can still use hosted tools (web search/file search) in this mode,
- function calling is improved.

**Prompting nuance for `none`**
- You can instruct the model to “plan before calling tools” and “reflect after tool results,” to reduce mistakes.
- But warn it not to become a “tool-calling zombie”: it should still reason at a high level *in the response* when needed (without internal reasoning tokens), and not just blindly chain tool calls.
- Add a “verify before executing” habit for longer runs (e.g., confirm constraints before taking an irreversible action).

---

## 5) Maximizing coding performance: planning → execution → recap

### 5.1 Add a “plan tool” for long-running work
Reasoning models often plan internally; a **plan tool** externalizes it so:
- users can see progress,
- the model stays anchored to milestones,
- you reduce “lost in the middle” failures.

**Recommended plan discipline**
- Use plan tool for medium+ tasks (multi-file work, new endpoints, multi-step debugging).
- Create **2–5 milestones/outcomes** (avoid micro-steps like “open file” or “run tests”).
- Exactly **one** item can be `in_progress` at a time.
- Don’t “jump” a task from pending → done without marking it in progress first.
- Keep plan status fresh (don’t go ~8 tool calls without updating).
- End-of-turn invariant: nothing left pending/in_progress; complete, cancel, or defer everything with brief reasons.
- If you show a plan in chat, mirror it into the plan tool (so chat and tool state agree).
- For tiny tasks (e.g., < ~10 lines), you can skip the plan tool.

**Example plan tool shape**
- `update_plan(merge: true, todos: [{id, content, status}, ...])`

### 5.2 Design system enforcement for frontend code
If you want UI output to match a design system:
- use Tailwind,
- enforce “tokens-first” styling.

**Token-based enforcement rules**
- No raw colors in JSX/CSS (no hex/hsl/rgb directly).
- Add/extend tokens in `globals.css` under `:root` and `.dark` (background, foreground, primary, etc.).
- If adding a brand accent: define `--brand`, `--brand-foreground`, and optional ring/muted/surface tokens first.
- Use Tailwind utilities wired to tokens (e.g., `bg-[hsl(var(--primary))]`, `text-[hsl(var(--foreground))]`).
- Default to neutral palette unless user explicitly requests a branded look; then map the brand into tokens first.

---

## 6) New tool types in GPT‑5.1 (coding)

### 6.1 `apply_patch`
`apply_patch` is a built-in tool to create/update/delete files via structured diffs.

**Why it matters**
- You don’t need a custom tool description; the Responses API manages it.
- Under the hood, it uses a freeform function call format.
- OpenAI reports reduced failure rates in testing when using the named tool.

**How it looks (conceptually)**
- You pass `tools=[{"type":"apply_patch"}]` in your response call.
- The model returns an `apply_patch_call` containing:
  - operation type: `create_file` | `update_file` | `delete_file`
  - a diff payload
  - a path
- Your system executes the patch and returns an `apply_patch_call_output` with:
  - `call_id`
  - `status` (completed/failed)
  - `output` (logs, errors, etc.)

### 6.2 `shell`
`shell` is another built-in tool for controlled command execution.

**Typical loop**
1) Model proposes commands (shell tool call).
2) Your integration executes them with constraints (timeout/output length).
3) You return stdout/stderr + exit details.
4) Model iterates until task complete.

**What the API surface includes**
- a `shell_call` object with:
  - commands list
  - `timeout_ms` (example in guide: 120000)
  - `max_output_length` (example: 4096)
- You reply with a `shell_call_output` that includes:
  - stdout / stderr
  - exit code info

---

## 7) How to metaprompt effectively (debug your prompts like code)

The guide’s thesis: prompt iteration is high leverage, but small changes can have big unintended steering effects.

### 7.1 Use failure traces + metaprompting instead of guessing
Instead of “manually eyeballing” the system prompt, ask GPT‑5.1 to diagnose:
- what failure modes are happening,
- what lines likely cause them,
- and how contradictions produce the observed behavior.

### 7.2 Step-by-step metaprompt workflow

**Step 1 — Diagnose (analysis call)**
Give:
- the current system prompt,
- a small batch of failures (query, tools actually called, final answer snippet, eval signal).

Ask for:
- distinct failure modes,
- the prompt drivers (lines/sections) that cause them,
- why those drivers matter.

Return structure like:
- `failure_modes:`
  - `name`
  - `description`
  - `prompt_drivers` (line/paraphrase + explanation)

**Important tip:** Group feedback logically. If you include too many different failure types at once, the model may struggle to unify them. Split into separate diagnosis prompts when needed.

**Step 2 — Patch (implementation call)**
Provide:
- original system prompt,
- the failure-mode analysis from step 1.

Ask for:
- a surgical revision, not a full rewrite.

Constraints that help:
- don’t redesign the agent from scratch,
- prefer small explicit edits,
- resolve contradictions and redundancies,
- make tradeoffs explicit (when to prioritize concision vs completeness; when tools must vs must not be called),
- keep overall length/structure similar unless consolidation removes obvious duplication.

Output:
1) `patch_notes` (what changed + why)  
2) `revised_system_prompt` (drop-in replacement)

### 7.3 Iterate with evals
- Re-run representative queries after each patch to watch for regressions.
- As your system grows (more tools, broader scope), consider metaprompting additions too—this keeps tool boundaries crisp rather than slowly turning into an inconsistent blob.

---

## 8) Quick “copy me” building blocks (rewritten templates)

### 8.1 Compact response spec (drop-in)
- Prefer short, direct responses.
- Use bullets only when user asks for a list/options/checklist.
- Keep code snippets rare and tiny; otherwise reference file/symbols.
- Don’t paste logs unless asked or necessary.

### 8.2 User update spec (drop-in)
- Before tools: 3-bullet plan (goal/constraints/next).
- During tools: 1–2 sentences when something changes; include at least one concrete new finding each time.
- If heads-down: say why + when you’ll report back.
- End: recap milestones with status; address every promised item.

### 8.3 Persistence spec (drop-in)
- Act like an autonomous senior pair-programmer.
- Finish end-to-end in one turn when feasible.
- Don’t stop at partial analysis; implement + verify + explain outcome.
- If intent is unclear, make reasonable defaults instead of stalling.

---

## 9) What’s next (from the guide)
- GPT‑5.1 extends GPT‑5 with stronger calibration, more steerability, new coding tools, and `none` reasoning mode.
- Official docs + blog are linked from the bottom of the guide.

---

## Appendix: Suggested “prompt layout” for a production agent

1) Identity / role  
2) Primary objective (what “good” looks like)  
3) Scope boundaries (what not to do)  
4) Tone & style rules (including when to be brief)  
5) Output format rules (verbosity, snippet budgets)  
6) Tool rules (when to call, must/never, examples)  
7) Progress updates spec (user updates/preambles)  
8) Persistence / completeness rules  
9) Planning discipline (plan tool rules)  
10) Verification and safety checks

